{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29247982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/khoihm/llava15/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: llava-v1.5-7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/khoihm/llava15/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/user/khoihm/llava15/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.append('models/LLaVA')\n",
    "\n",
    "from llava.constants import (\n",
    "    IMAGE_TOKEN_INDEX,\n",
    "    DEFAULT_IMAGE_TOKEN,\n",
    "    DEFAULT_IM_START_TOKEN,\n",
    "    DEFAULT_IM_END_TOKEN,\n",
    "    IMAGE_PLACEHOLDER,\n",
    ")\n",
    "from llava.conversation import conv_templates\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import (\n",
    "    process_images,\n",
    "    tokenizer_image_token,\n",
    "    get_model_name_from_path,\n",
    ")\n",
    "\n",
    "\n",
    "disable_torch_init()\n",
    "\n",
    "model_name = get_model_name_from_path(\"liuhaotian/llava-v1.5-7b\")\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    \"liuhaotian/llava-v1.5-7b\",\n",
    "    None,\n",
    "    model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1297a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The image features a man wearing a red jacket and ski gear, standing on a snow-covered slope. He is holding a pair of skis and appears to be preparing to ski down the hill. The man is positioned in the center of the scene, with the skis held in his hands.\n",
      "\n",
      "In the background, there are a few other people scattered around the slope, possibly enjoying the winter sports activities as well. The scene captures the excitement and fun of skiing on a sunny day.</s>\n"
     ]
    }
   ],
   "source": [
    "with open('data/test.jsonl','r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "line = lines[1]\n",
    "data = json.loads(line)\n",
    "path = '/home/user/khoihm/val2014/' + data['image']\n",
    "\n",
    "image = Image.open(path).convert(\"RGB\")\n",
    "image_tensor = process_images([image], image_processor, model.config)\n",
    "image_tensor = image_tensor.to(model.device, dtype=torch.float16)\n",
    "image_sizes = [image.size]\n",
    "query = \"Describe this image.\"\n",
    "\n",
    "qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + query\n",
    "\n",
    "# Create conversation and format prompt\n",
    "conv = conv_templates[\"llava_v1\"].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "# Tokenize input\n",
    "input_ids = tokenizer_image_token(\n",
    "    prompt, \n",
    "    tokenizer, \n",
    "    IMAGE_TOKEN_INDEX, \n",
    "    return_tensors=\"pt\",\n",
    ").unsqueeze(0).to(model.device)\n",
    "# Generate response with attention\n",
    "with torch.inference_mode():\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        images=image_tensor.unsqueeze(0),\n",
    "        image_sizes=image_sizes,\n",
    "        do_sample=False,\n",
    "        output_scores = True,\n",
    "        output_attentions = True,\n",
    "        return_dict_in_generate = True,\n",
    "        max_new_tokens=2048\n",
    "    )\n",
    "    \n",
    "print(tokenizer.decode(outputs.sequences[0], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b232a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The image features a man wearing a red jacket and ski gear, standing on a snow-covered slope. In his hand, he holds a pair of skis, ready to ski down the hill. The man appears to be enjoying his time on the snow-covered slope, possibly taking a break or preparing to continue skiing.\n",
      "\n",
      "There are a few other people in the scene, but they are not the main focus of the image. The main subject is the man in the red jacket, who is the center of attention as he stands on his skis and looks out over the snowy landscape.</s>\n"
     ]
    }
   ],
   "source": [
    "prefix = 'The image features a man wearing a red jacket and ski gear, standing on a snow-covered slope. In'\n",
    "\n",
    "prefix = tokenizer.encode(prefix, return_tensors=\"pt\").to(model.device)[0]\n",
    "query = \"Describe this image.\"\n",
    "\n",
    "qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + query\n",
    "\n",
    "# Create conversation and format prompt\n",
    "conv = conv_templates[\"llava_v1\"].copy()\n",
    "conv.append_message(conv.roles[0], qs)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "# Tokenize input\n",
    "input_ids = tokenizer_image_token(\n",
    "    prompt, \n",
    "    tokenizer, \n",
    "    IMAGE_TOKEN_INDEX, \n",
    "    return_tensors=\"pt\",\n",
    ").unsqueeze(0).to(model.device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    new_outputs = model.generate_with_prefix(\n",
    "        input_ids,\n",
    "        images=image_tensor.unsqueeze(0),\n",
    "        prefix = prefix,\n",
    "        image_sizes=image_sizes,\n",
    "        max_new_tokens=2048\n",
    "    )\n",
    "print(tokenizer.decode(new_outputs[0],skip_special_tokens=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
